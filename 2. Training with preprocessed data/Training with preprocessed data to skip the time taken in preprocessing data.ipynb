{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oMF2OH0vtPkT"
   },
   "outputs": [],
   "source": [
    "# All necessary imports to perform the training\n",
    "from processedDataHelper import *\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset,DataLoader\n",
    "from myModelHelper import *\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim import Optimizer\n",
    "import  math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "vtT6P7FntPkW",
    "outputId": "8020c598-5157-440d-c40d-6fe03768e87e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive/\n"
     ]
    }
   ],
   "source": [
    "# Mount the google drive to save the finally loaded model to drive\n",
    "from google.colab import files,drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TFOLVQH-tPkb"
   },
   "outputs": [],
   "source": [
    "class SentimentNetwork(nn.Module):\n",
    "  def __init__(self,vocabulary_size,output_size,embedding_dimension,hidden_dimension,number_of_layers,dropout_probability=0.5):\n",
    "    super(SentimentNetwork,self).__init__()\n",
    "    # class data for weight matrix size\n",
    "    self.output_size=output_size\n",
    "    self.number_of_layers=number_of_layers\n",
    "    self.hidden_dimension=hidden_dimension\n",
    "    # create the embedding layer to reduce dimension \n",
    "    # and LSTM layer containing LSTM cells \n",
    "    self.embedding=nn.Embedding(vocabulary_size,embedding_dimension)\n",
    "    self.lstm=nn.LSTM(embedding_dimension,hidden_dimension,number_of_layers,dropout=dropout_probability,batch_first=True)\n",
    "    \n",
    "    # Create dropout layer as a regularization method to reduct overfitting\n",
    "    # this will disable some units in forward pass, thus preventing \n",
    "    # a particular set of node's weights getting updated while others remain unused\n",
    "    self.dropout=nn.Dropout(dropout_probability)\n",
    "    \n",
    "    # attach final  linear layer with sigmoid function\n",
    "    self.finalLayer=nn.Linear(hidden_dimension,output_size)\n",
    "    self.sigmoid=nn.Sigmoid()\n",
    "   \n",
    "  def forward(self,x,hidden):\n",
    "    batch_size=x.size(0)\n",
    "    embedding_output=self.embedding(x)\n",
    "    \n",
    "    #lstm will take the current input and hidden state as input \n",
    "    # and will generate the output to be feed at the linear layer\n",
    "    lstm_output,hidden=self.lstm(embedding_output,hidden)\n",
    "    lstm_output=lstm_output.contiguous().view(-1,self.hidden_dimension)\n",
    "    \n",
    "    output=self.dropout(lstm_output)\n",
    "    output=self.finalLayer(output)\n",
    "    \n",
    "    #call the sigmoid function on current output of final layer\n",
    "    sigmoid_output=self.sigmoid(output)\n",
    "    sigmoid_output=sigmoid_output.view(batch_size,-1)\n",
    "    #only get the last position output for all batches\n",
    "    sigmoid_output=sigmoid_output[:,-1]\n",
    "    \n",
    "    #current sigmoid output and a hidden state to be fed as input for next pass\n",
    "    # into the LSTM cells, so that they will be dependent on the previous state\n",
    "    return sigmoid_output,hidden\n",
    "  \n",
    "  def initialize_hidden_state(self,batch_size):\n",
    "    # At first the hidden state will not hold any information, hence we need to\n",
    "    # initialize them with zeros\n",
    "    # Number_of_Layers x Batch_Size x Hidden_Dimension\n",
    "    weight=next(self.parameters()).data\n",
    "    if(torch.cuda.is_available()):\n",
    "      # if GPU is available then initialize the weights parallely\n",
    "      hidden=(weight.new(self.number_of_layers,batch_size,self.hidden_dimension).zero_().cuda(),weight.new(self.number_of_layers,batch_size,self.hidden_dimension).zero_().cuda())\n",
    "    else:\n",
    "      hidden=(weight.new(self.number_of_layers,batch_size,self.hidden_dimension).zero_(),weight.new(self.number_of_layers,batch_size,self.hidden_dimension).zero_())\n",
    "      \n",
    "    return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SIiG19NytPkh"
   },
   "outputs": [],
   "source": [
    "def buildNetwork():\n",
    "  #Our model parameters\n",
    "  vocabulary_size=len(vocab_to_int)+1\n",
    "  output_size=1\n",
    "  embedding_dimension=400\n",
    "  hidden_dimension=256\n",
    "  number_of_layers=3\n",
    "  \n",
    "  model=SentimentNetwork(vocabulary_size,output_size,embedding_dimension,hidden_dimension,number_of_layers)\n",
    "  \n",
    "  # Alpha value(Step size)\n",
    "  learning_rate=0.001\n",
    "  \n",
    "  # Error calculating formula (Mean Square Error)\n",
    "  criterion = nn.MSELoss() \n",
    " \n",
    "  #Adam optimization technique for first-order gradient-based optimization\n",
    "  #optimizer=AdamOptimizerAlgorithm(model.parameters(),lr=learning_rate)\n",
    "  optimizer=torch.optim.Adam(model.parameters(),lr=learning_rate)\n",
    "  return model,criterion,optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O5C0_cfJtPkj"
   },
   "outputs": [],
   "source": [
    "def trainNetwork(model,epochs,print_interval,criterion,optimizer):\n",
    "  Iteration=[]\n",
    "  Training_Loss=[]\n",
    "  Validation_Loss=[]\n",
    "  \n",
    "  minimum_validation_loss=np.Inf\n",
    "  \n",
    "  # Since each epoch goes over all data and\n",
    "  # each iteration goes over the data in batches\n",
    "  count=0\n",
    "  \n",
    "  # move model to GPU \n",
    "  #model.cuda()\n",
    "  \n",
    "  #put the model into training model so that the gradients will \n",
    "  # be calculated\n",
    "  model.train()\n",
    "  for i in range(epochs):\n",
    "    # for each epoch perform a forward pass for all batches\n",
    "    # and around epoch 4 reduce the learning rate\n",
    "    hidden_state=model.initialize_hidden_state(batch_size)\n",
    "    \n",
    "    if(i==3):\n",
    "      print(\"\\n\\nReducing the learning rate!\\n\")\n",
    "      optimizer=torch.optim.Adam(model.parameters(),lr=0.0000002)\n",
    "    \n",
    "    for inputs,labels in train_loader:\n",
    "      count+=1\n",
    "      # move the data to GPU\n",
    "      inputs,labels=inputs.cuda(),labels.cuda()\n",
    "      \n",
    "      #create new variable for hidden state otherwise it will include all\n",
    "      #pervious states\n",
    "      hidden_state=tuple([element.data for element in hidden_state])\n",
    "      \n",
    "      model.zero_grad()\n",
    "      \n",
    "      inputs=inputs.long()\n",
    "      output,hidden_state=model(inputs,hidden_state)\n",
    "      \n",
    "      #calculate the loss to backpropagare to model\n",
    "      #loss=torch.sqrt(criterion(output.squeeze(),labels.float()))\n",
    "      loss=criterion(output.squeeze(),labels.float())\n",
    "      loss.backward()\n",
    "\n",
    "      \n",
    "      #nn.utils.clip_grad_norm_(model.parameters(),clip)\n",
    "      optimizer.step()\n",
    "      \n",
    "      if(count%print_interval==0):\n",
    "        temp_hidden=model.initialize_hidden_state(batch_size)\n",
    "        temp_losses=[]\n",
    "        model.eval()\n",
    "        for inputs,labels in validation_loader:\n",
    "          temp_hidden=tuple([element.data for element in temp_hidden])\n",
    "          inputs,labels=inputs.cuda().long(),labels.cuda()\n",
    "          \n",
    "          output,temp_hidden=model(inputs,temp_hidden)\n",
    "          validation_loss=criterion(output.squeeze(),labels.float())\n",
    "          temp_losses.append(validation_loss.item())\n",
    "        \n",
    "        model.train()\n",
    "        print(\"Epoch: {}\\tIteration: {}\\tTraining Loss: {:.7f}\\tValidation Loss: {:.7f}\".format(\n",
    "        (i+1),count,loss.item(),np.mean(temp_losses)))\n",
    "        Iteration.append(count)\n",
    "        Training_Loss.append(loss.item())\n",
    "        Validation_Loss.append(np.mean(temp_losses))\n",
    "        \n",
    "        if np.mean(temp_losses)<minimum_validation_loss:\n",
    "            save_checkpoint(model,\"checkpoint.pth\")\n",
    "            minimum_validation_loss=np.mean(temp_losses)\n",
    "            print(\"Validation loss decreased  hence saving checkpoint successfully\")\n",
    "                  \n",
    "         \n",
    "\n",
    "    #Plot the Training and Validation loss\n",
    "  plt.plot(Iteration,Training_Loss)\n",
    "  plt.plot(Iteration,Validation_Loss)\n",
    "  plt.xlabel('Iteration')\n",
    "  plt.ylabel('Loss')\n",
    "  plt.ylim(0.0,1.0)\n",
    "  plt.legend(['Training Loss','Validation Loss'], loc='upper left')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oJrUxK54tPkm"
   },
   "outputs": [],
   "source": [
    "def save_checkpoint(model,fileLocation):\n",
    "  # save the current state_dict which contains all the weights of the network\n",
    "  torch.save(model.state_dict(),fileLocation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n9VpgrwttPkp"
   },
   "outputs": [],
   "source": [
    "# To build the network with same architecture and load the checkpoint file\n",
    "def load_Checkpoint(fileLocation):\n",
    "  model,criterion,optimizer=buildNetwork()\n",
    "  model.load_state_dict(torch.load(fileLocation))\n",
    "  return model,criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0ryC2bp_tPkr"
   },
   "outputs": [],
   "source": [
    "def checkAccuracy(model,test_loader):\n",
    "  #move model to GPU\n",
    "  model.cuda()\n",
    "  \n",
    "  test_losses=[]\n",
    "  correct_prediction=0\n",
    "  \n",
    "  #set initial state to zero\n",
    "  hidden_state=model.initialize_hidden_state(batch_size)\n",
    "  \n",
    "  # set the model into evaluation mode, so that we don't need to calculate\n",
    "  # the gradients\n",
    "  model.eval()\n",
    "  \n",
    "  for inputs,labels in test_loader:\n",
    "    \n",
    "    # move the data and labels into GPU\n",
    "    inputs,labels=inputs.cuda().long(),labels.cuda().long()\n",
    "    \n",
    "    output,hidden_state=model(inputs,hidden_state)\n",
    "    # labels are initially long or int, we need to conver them into float\n",
    "    # so that loss cab be calculated in float value\n",
    "    test_loss=criterion(output.squeeze(),labels.float())\n",
    "    test_losses.append(test_loss.item())\n",
    "    \n",
    "    # get the prediction either 1 or 0\n",
    "    prediction=torch.round(output.squeeze())\n",
    "    \n",
    "    correct_tensor=prediction.eq(labels.float().view_as(prediction))   \n",
    "    correct=np.squeeze(correct_tensor.cpu().numpy())\n",
    "    correct_prediction+=np.sum(correct)\n",
    "  \n",
    "  print(\"Accuracy: {:.4f}\".format(correct_prediction/len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z60mOLDAtPk1"
   },
   "outputs": [],
   "source": [
    "# Tokenize passed sentences\n",
    "def tokenize_sentence(sentence):\n",
    "  sentence=sentence.lower()\n",
    "  \n",
    "  #remove punctuation\n",
    "  sentence=''.join([letter for letter in sentence if letter not in punctuation])\n",
    "  \n",
    "  test_words=sentence.split()\n",
    "  tokens=[]\n",
    "  sample=[]\n",
    "  for word in test_words:\n",
    "      if word in vocab_to_int:\n",
    "          sample.append(word)\n",
    "  tokens.append([vocab_to_int[word] for word in sample])\n",
    "  return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DsopvIMntPlA"
   },
   "outputs": [],
   "source": [
    "def predict(model,sentence,sequence_length=200):\n",
    "  #model.cuda()\n",
    "  #disable the gradient calculation to speedup the calculation, since we are only using for prediction\n",
    "  model.eval()\n",
    "  \n",
    "  test_ints=tokenize_sentence(sentence)\n",
    "  features=featuresPadding(test_ints,sequence_length)\n",
    "  feature_tensor=torch.from_numpy(features)\n",
    "  batch_size=feature_tensor.size(0)\n",
    "  \n",
    "  hidden_state=model.initialize_hidden_state(batch_size)\n",
    "  feature_tensor=feature_tensor.cuda().long()\n",
    "  output,hidden_state=model(feature_tensor,hidden_state)\n",
    "  prediction=torch.round(output.squeeze())\n",
    "  if(prediction.item()==0):\n",
    "    print(\"{:.4f}\\t Negative sentence!\".format(output.item()))\n",
    "  else:\n",
    "    print(\"{:.4f}\\t Positive sentence!\".format(output.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FjWzX3q1tPlE"
   },
   "outputs": [],
   "source": [
    "#location of preprocessed data\n",
    "features_location='ProcessedFeatures.npy'\n",
    "label_location='ProcessedEncodedLabels.npy'\n",
    "vocab_dict_location='ProcessedVocabToInt.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pr6PlEmYtPlI"
   },
   "outputs": [],
   "source": [
    "# Load the preprocessed data, Features=Inputs, Labels=Actual Outputs, VocabToInt=Word to integer mapping\n",
    "features=loadNumpyArray(features_location)\n",
    "encoded_labels=loadNumpyArray(label_location)\n",
    "vocab_to_int=loadDict(vocab_dict_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lFqJK4UttPlN"
   },
   "outputs": [],
   "source": [
    "#set the input sequence length to 200\n",
    "seq_length=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wihqQwxFtPlU"
   },
   "outputs": [],
   "source": [
    "#Create Train, Test, Validation set with 80% data into train set, and rest 20% divided into equal half for Test and Validation\n",
    "train_x,train_y,test_x,test_y,val_x,val_y=createTrainTestValidateData(0.8,features,encoded_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k7JxPd3ltPlc"
   },
   "outputs": [],
   "source": [
    "# Convert to tensor\n",
    "train_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
    "validation_data = TensorDataset(torch.from_numpy(val_x), torch.from_numpy(val_y))\n",
    "test_data = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))\n",
    "\n",
    "batch_size=100\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "validation_loader = DataLoader(validation_data, shuffle=True, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "7Ge-TjehtPlk",
    "outputId": "6b09d9fc-7103-4e5c-f166-4313847b0bea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: \t (40000, 200)\n",
      "Validation: \t (5000, 200)\n",
      "Test: \t\t (5000, 200)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training: \\t\",np.shape(train_x))\n",
    "print(\"Validation: \\t\",np.shape(val_x))\n",
    "print(\"Test: \\t\\t\",np.shape(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cuJjsOZltPmG"
   },
   "outputs": [],
   "source": [
    "#Build Network\n",
    "model,criterion,optimizer=buildNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 146
    },
    "colab_type": "code",
    "id": "RqtX787PtPmJ",
    "outputId": "f0929cc3-c7cd-43eb-c82b-42dd0130edb3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentimentNetwork(\n",
       "  (embedding): Embedding(181686, 400)\n",
       "  (lstm): LSTM(400, 256, num_layers=3, batch_first=True, dropout=0.5)\n",
       "  (dropout): Dropout(p=0.5)\n",
       "  (finalLayer): Linear(in_features=256, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Move model to GPU, since Google Colab has been used with GPU enabled\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mGDoHi61tPmP"
   },
   "outputs": [],
   "source": [
    "print_interval = 100\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "R5MwjfhptPmT",
    "outputId": "8cf873dd-349f-48a8-8737-19b033536c44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\tIteration: 100\tTraining Loss: 0.6409116\tValidation Loss: 0.6310162\n",
      "Validation loss decreased  hence saving checkpoint successfully\n",
      "Epoch: 1\tIteration: 200\tTraining Loss: 0.4938466\tValidation Loss: 0.5405232\n",
      "Validation loss decreased  hence saving checkpoint successfully\n",
      "Epoch: 1\tIteration: 300\tTraining Loss: 0.4187748\tValidation Loss: 0.4741382\n",
      "Validation loss decreased  hence saving checkpoint successfully\n",
      "Epoch: 1\tIteration: 400\tTraining Loss: 0.5295486\tValidation Loss: 0.4390899\n",
      "Validation loss decreased  hence saving checkpoint successfully\n",
      "Epoch: 2\tIteration: 500\tTraining Loss: 0.3579498\tValidation Loss: 0.3981382\n",
      "Validation loss decreased  hence saving checkpoint successfully\n",
      "Epoch: 2\tIteration: 600\tTraining Loss: 0.3697390\tValidation Loss: 0.3833222\n",
      "Validation loss decreased  hence saving checkpoint successfully\n",
      "Epoch: 2\tIteration: 700\tTraining Loss: 0.2842821\tValidation Loss: 0.3537847\n",
      "Validation loss decreased  hence saving checkpoint successfully\n",
      "Epoch: 2\tIteration: 800\tTraining Loss: 0.3373912\tValidation Loss: 0.3664070\n",
      "Epoch: 3\tIteration: 900\tTraining Loss: 0.3273340\tValidation Loss: 0.3550954\n",
      "Epoch: 3\tIteration: 1000\tTraining Loss: 0.3641517\tValidation Loss: 0.3617842\n",
      "Epoch: 3\tIteration: 1100\tTraining Loss: 0.3111466\tValidation Loss: 0.3492852\n",
      "Validation loss decreased  hence saving checkpoint successfully\n",
      "Epoch: 3\tIteration: 1200\tTraining Loss: 0.3011726\tValidation Loss: 0.3471850\n",
      "Validation loss decreased  hence saving checkpoint successfully\n",
      "\n",
      "\n",
      "Reducing the learning rate!\n",
      "\n",
      "Epoch: 4\tIteration: 1300\tTraining Loss: 0.2852843\tValidation Loss: 0.3417963\n",
      "Validation loss decreased  hence saving checkpoint successfully\n",
      "Epoch: 4\tIteration: 1400\tTraining Loss: 0.1915018\tValidation Loss: 0.3432700\n",
      "Epoch: 4\tIteration: 1500\tTraining Loss: 0.1669726\tValidation Loss: 0.3415619\n",
      "Validation loss decreased  hence saving checkpoint successfully\n",
      "Epoch: 4\tIteration: 1600\tTraining Loss: 0.1643650\tValidation Loss: 0.3430348\n",
      "Epoch: 5\tIteration: 1700\tTraining Loss: 0.2106061\tValidation Loss: 0.3398889\n",
      "Validation loss decreased  hence saving checkpoint successfully\n",
      "Epoch: 5\tIteration: 1800\tTraining Loss: 0.1404882\tValidation Loss: 0.3354329\n",
      "Validation loss decreased  hence saving checkpoint successfully\n",
      "Epoch: 5\tIteration: 1900\tTraining Loss: 0.1130219\tValidation Loss: 0.3360439\n",
      "Epoch: 5\tIteration: 2000\tTraining Loss: 0.2037523\tValidation Loss: 0.3398515\n",
      "Epoch: 6\tIteration: 2100\tTraining Loss: 0.2496022\tValidation Loss: 0.3366521\n",
      "Epoch: 6\tIteration: 2200\tTraining Loss: 0.1947723\tValidation Loss: 0.3377884\n",
      "Epoch: 6\tIteration: 2300\tTraining Loss: 0.1518145\tValidation Loss: 0.3339793\n",
      "Validation loss decreased  hence saving checkpoint successfully\n",
      "Epoch: 6\tIteration: 2400\tTraining Loss: 0.2121463\tValidation Loss: 0.3361756\n",
      "Epoch: 7\tIteration: 2500\tTraining Loss: 0.2083155\tValidation Loss: 0.3353409\n",
      "Epoch: 7\tIteration: 2600\tTraining Loss: 0.1831770\tValidation Loss: 0.3344999\n",
      "Epoch: 7\tIteration: 2700\tTraining Loss: 0.1125378\tValidation Loss: 0.3326961\n",
      "Validation loss decreased  hence saving checkpoint successfully\n",
      "Epoch: 7\tIteration: 2800\tTraining Loss: 0.1811990\tValidation Loss: 0.3336973\n",
      "Epoch: 8\tIteration: 2900\tTraining Loss: 0.1784146\tValidation Loss: 0.3323375\n",
      "Validation loss decreased  hence saving checkpoint successfully\n",
      "Epoch: 8\tIteration: 3000\tTraining Loss: 0.0905761\tValidation Loss: 0.3322364\n",
      "Validation loss decreased  hence saving checkpoint successfully\n",
      "Epoch: 8\tIteration: 3100\tTraining Loss: 0.1707828\tValidation Loss: 0.3335523\n",
      "Epoch: 8\tIteration: 3200\tTraining Loss: 0.2044033\tValidation Loss: 0.3291482\n",
      "Validation loss decreased  hence saving checkpoint successfully\n",
      "Epoch: 9\tIteration: 3300\tTraining Loss: 0.2087672\tValidation Loss: 0.3306858\n",
      "Epoch: 9\tIteration: 3400\tTraining Loss: 0.1279559\tValidation Loss: 0.3295981\n",
      "Epoch: 9\tIteration: 3500\tTraining Loss: 0.1505526\tValidation Loss: 0.3301006\n",
      "Epoch: 9\tIteration: 3600\tTraining Loss: 0.1876728\tValidation Loss: 0.3311945\n",
      "Epoch: 10\tIteration: 3700\tTraining Loss: 0.1923246\tValidation Loss: 0.3285444\n",
      "Validation loss decreased  hence saving checkpoint successfully\n",
      "Epoch: 10\tIteration: 3800\tTraining Loss: 0.1807820\tValidation Loss: 0.3331996\n",
      "Epoch: 10\tIteration: 3900\tTraining Loss: 0.1255747\tValidation Loss: 0.3273045\n",
      "Validation loss decreased  hence saving checkpoint successfully\n",
      "Epoch: 10\tIteration: 4000\tTraining Loss: 0.0771689\tValidation Loss: 0.3317630\n",
      "Epoch: 11\tIteration: 4100\tTraining Loss: 0.1918450\tValidation Loss: 0.3266459\n",
      "Validation loss decreased  hence saving checkpoint successfully\n",
      "Epoch: 11\tIteration: 4200\tTraining Loss: 0.1375480\tValidation Loss: 0.3285517\n",
      "Epoch: 11\tIteration: 4300\tTraining Loss: 0.1959182\tValidation Loss: 0.3283821\n",
      "Epoch: 11\tIteration: 4400\tTraining Loss: 0.2208972\tValidation Loss: 0.3315913\n",
      "Epoch: 12\tIteration: 4500\tTraining Loss: 0.1818059\tValidation Loss: 0.3289268\n",
      "Epoch: 12\tIteration: 4600\tTraining Loss: 0.0736426\tValidation Loss: 0.3296557\n",
      "Epoch: 12\tIteration: 4700\tTraining Loss: 0.1085411\tValidation Loss: 0.3290294\n",
      "Epoch: 12\tIteration: 4800\tTraining Loss: 0.1732661\tValidation Loss: 0.3287434\n",
      "Epoch: 13\tIteration: 4900\tTraining Loss: 0.2075359\tValidation Loss: 0.3264684\n",
      "Validation loss decreased  hence saving checkpoint successfully\n",
      "Epoch: 13\tIteration: 5000\tTraining Loss: 0.1863580\tValidation Loss: 0.3304021\n",
      "Epoch: 13\tIteration: 5100\tTraining Loss: 0.1743604\tValidation Loss: 0.3327085\n",
      "Epoch: 13\tIteration: 5200\tTraining Loss: 0.2214079\tValidation Loss: 0.3295552\n",
      "Epoch: 14\tIteration: 5300\tTraining Loss: 0.1958887\tValidation Loss: 0.3274568\n",
      "Epoch: 14\tIteration: 5400\tTraining Loss: 0.2065652\tValidation Loss: 0.3324205\n",
      "Epoch: 14\tIteration: 5500\tTraining Loss: 0.2148947\tValidation Loss: 0.3312844\n",
      "Epoch: 14\tIteration: 5600\tTraining Loss: 0.1566016\tValidation Loss: 0.3307428\n",
      "Epoch: 15\tIteration: 5700\tTraining Loss: 0.1616233\tValidation Loss: 0.3328321\n",
      "Epoch: 15\tIteration: 5800\tTraining Loss: 0.1637350\tValidation Loss: 0.3300575\n",
      "Epoch: 15\tIteration: 5900\tTraining Loss: 0.0815195\tValidation Loss: 0.3295477\n",
      "Epoch: 15\tIteration: 6000\tTraining Loss: 0.2555203\tValidation Loss: 0.3310944\n",
      "Epoch: 16\tIteration: 6100\tTraining Loss: 0.1373838\tValidation Loss: 0.3275329\n",
      "Epoch: 16\tIteration: 6200\tTraining Loss: 0.1035387\tValidation Loss: 0.3289170\n",
      "Epoch: 16\tIteration: 6300\tTraining Loss: 0.1396382\tValidation Loss: 0.3289620\n",
      "Epoch: 16\tIteration: 6400\tTraining Loss: 0.1973514\tValidation Loss: 0.3296827\n",
      "Epoch: 17\tIteration: 6500\tTraining Loss: 0.1082630\tValidation Loss: 0.3283946\n",
      "Epoch: 17\tIteration: 6600\tTraining Loss: 0.1865412\tValidation Loss: 0.3311783\n",
      "Epoch: 17\tIteration: 6700\tTraining Loss: 0.1658169\tValidation Loss: 0.3319550\n",
      "Epoch: 17\tIteration: 6800\tTraining Loss: 0.0932972\tValidation Loss: 0.3296738\n",
      "Epoch: 18\tIteration: 6900\tTraining Loss: 0.1778122\tValidation Loss: 0.3338579\n",
      "Epoch: 18\tIteration: 7000\tTraining Loss: 0.0865773\tValidation Loss: 0.3309076\n",
      "Epoch: 18\tIteration: 7100\tTraining Loss: 0.1634359\tValidation Loss: 0.3310143\n",
      "Epoch: 18\tIteration: 7200\tTraining Loss: 0.1468602\tValidation Loss: 0.3306011\n",
      "Epoch: 19\tIteration: 7300\tTraining Loss: 0.2250934\tValidation Loss: 0.3314275\n",
      "Epoch: 19\tIteration: 7400\tTraining Loss: 0.1819504\tValidation Loss: 0.3305684\n",
      "Epoch: 19\tIteration: 7500\tTraining Loss: 0.1434057\tValidation Loss: 0.3340919\n",
      "Epoch: 19\tIteration: 7600\tTraining Loss: 0.1204693\tValidation Loss: 0.3328384\n",
      "Epoch: 20\tIteration: 7700\tTraining Loss: 0.2181827\tValidation Loss: 0.3313213\n",
      "Epoch: 20\tIteration: 7800\tTraining Loss: 0.2679305\tValidation Loss: 0.3353497\n",
      "Epoch: 20\tIteration: 7900\tTraining Loss: 0.1270612\tValidation Loss: 0.3315550\n",
      "Epoch: 20\tIteration: 8000\tTraining Loss: 0.1602916\tValidation Loss: 0.3333786\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmNWyx9Lu4L8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training Time: 19.56415031750997 minutes\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time=time.time()\n",
    "trainNetwork(model,epochs,print_interval,criterion,optimizer)\n",
    "print(\"\\n\\nTraining Time: {} minutes\".format((time.time()-start_time)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wV7zn5YNtPmX"
   },
   "outputs": [],
   "source": [
    "#Checkpoint Saving Location\n",
    "fileLocation='/content/drive/My Drive/SEM-IV Project/SentimentAnalysisCheckpoint.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "-ZdA0KAttPmc",
    "outputId": "e6641a9c-7022-4788-f847-5e03bdb5f015"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8616\n"
     ]
    }
   ],
   "source": [
    "# Accuracy on Test Data for Overfitted model\n",
    "checkAccuracy(model,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "0XAi2jy5431o",
    "outputId": "eed9585b-6456-4a6f-97e4-fba76a1848ac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function torch.cuda.empty_cache>"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clear the CUDA Cache to clear GPU Memory\n",
    "torch.cuda.empty_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GHTHvShF44Md"
   },
   "outputs": [],
   "source": [
    "# Load the Saved Model \n",
    "model,criterion=load_Checkpoint('checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "KQr4MCDT52wE",
    "outputId": "395297db-6fff-4133-fe43-51143cde4f4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8578\n"
     ]
    }
   ],
   "source": [
    "# Accuracy on test data for saved model when validatio loss was decreased\n",
    "checkAccuracy(model,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "t1iP7CMd444C",
    "outputId": "0dbe4b16-487c-4212-ba02-58c8fb67c0d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 334020\n",
      "-rw-r--r-- 1 root root 297606517 Jun 21 07:32 checkpoint.pth\n",
      "drwx------ 3 root root      4096 Jun 21 06:25 drive\n",
      "-rw-r--r-- 1 root root      2865 Jun 21 06:25 myModelHelper.py\n",
      "-rw-r--r-- 1 root root       275 Jun 21 06:25 processedDataHelper.py\n",
      "-rw-r--r-- 1 root root    200128 Jun 21 06:25 ProcessedEncodedLabels.npy\n",
      "-rw-r--r-- 1 root root  40000128 Jun 21 06:32 ProcessedFeatures.npy\n",
      "-rw-r--r-- 1 root root   4199760 Jun 21 06:26 ProcessedVocabToInt.npy\n",
      "drwxr-xr-x 2 root root      4096 Jun 21 06:26 __pycache__\n",
      "drwxr-xr-x 1 root root      4096 Jun 18 16:14 sample_data\n"
     ]
    }
   ],
   "source": [
    "!ls -l"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Sentiment Analysis 21 June.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
