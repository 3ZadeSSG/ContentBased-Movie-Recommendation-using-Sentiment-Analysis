{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment Analysis using Stanford AI Dataset.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/3ZadeSSG/Minor-Project-Sentiment-Analysis/blob/master/Sentiment_Analysis_using_Stanford_AI_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "k3kr18m0qK7s",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files,drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "z523O_B3qQR0",
        "outputId": "d7f82952-c7f5-4594-9dde-4ac7ff2b1aa1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Hgkd5h8BG3N-",
        "outputId": "265c6c26-934e-4fed-ff48-36b20cbf8775",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "# Get the generated helper functions to process the data and create proper datasets to be converted into tensors\n",
        "!wget -c https://raw.githubusercontent.com/3ZadeSSG/Minor-Project-Sentiment-Analysis/master/myModelHelper.py"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-04-10 18:34:19--  https://raw.githubusercontent.com/3ZadeSSG/Minor-Project-Sentiment-Analysis/master/myModelHelper.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2790 (2.7K) [text/plain]\n",
            "Saving to: ‘myModelHelper.py’\n",
            "\n",
            "\rmyModelHelper.py      0%[                    ]       0  --.-KB/s               \rmyModelHelper.py    100%[===================>]   2.72K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-04-10 18:34:19 (28.6 MB/s) - ‘myModelHelper.py’ saved [2790/2790]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "85fw4k4rHawu",
        "outputId": "5ebf52ef-df51-43ca-92d2-07b3a1858104",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "# Get data directly from url\n",
        "!wget http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-04-07 14:21:35--  http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "Resolving ai.stanford.edu (ai.stanford.edu)... 171.64.68.10\n",
            "Connecting to ai.stanford.edu (ai.stanford.edu)|171.64.68.10|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 84125825 (80M) [application/x-gzip]\n",
            "Saving to: ‘aclImdb_v1.tar.gz’\n",
            "\n",
            "aclImdb_v1.tar.gz   100%[===================>]  80.23M  19.2MB/s    in 7.0s    \n",
            "\n",
            "2019-04-07 14:21:42 (11.5 MB/s) - ‘aclImdb_v1.tar.gz’ saved [84125825/84125825]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Fzb4-4g-Hhk1",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Extract data\n",
        "!tar -xvzf aclImdb_v1.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "z48JUwW7GYeB",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset,DataLoader\n",
        "from myModelHelper import *\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "A0zDAkRQGp-O",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class SentimentNetwork(nn.Module):\n",
        "  def __init__(self,vocabulary_size,output_size,embedding_dimension,hidden_dimension,number_of_layers,dropout_probability=0.5):\n",
        "    super(SentimentNetwork,self).__init__()\n",
        "    # class data for weight matrix size\n",
        "    self.output_size=output_size\n",
        "    self.number_of_layers=number_of_layers\n",
        "    self.hidden_dimension=hidden_dimension\n",
        "    # create the embedding layer to reduce dimension \n",
        "    # and LSTM layer containing LSTM cells \n",
        "    self.embedding=nn.Embedding(vocabulary_size,embedding_dimension)\n",
        "    self.lstm=nn.LSTM(embedding_dimension,hidden_dimension,number_of_layers,dropout=dropout_probability,batch_first=True)\n",
        "    \n",
        "    # Create dropout layer as a regularization method to reduct overfitting\n",
        "    # this will disable some units in forward pass, thus preventing \n",
        "    # a particular set of node's weights getting updated while others remain unused\n",
        "    self.dropout=nn.Dropout(dropout_probability)\n",
        "    \n",
        "    # attach final  linear layer with sigmoid function\n",
        "    self.finalLayer=nn.Linear(hidden_dimension,output_size)\n",
        "    self.sigmoid=nn.Sigmoid()\n",
        "   \n",
        "  def forward(self,x,hidden):\n",
        "    batch_size=x.size(0)\n",
        "    embedding_output=self.embedding(x)\n",
        "    \n",
        "    #lstm will take the current input and hidden state as input \n",
        "    # and will generate the output to be feed at the linear layer\n",
        "    lstm_output,hidden=self.lstm(embedding_output,hidden)\n",
        "    lstm_output=lstm_output.contiguous().view(-1,self.hidden_dimension)\n",
        "    \n",
        "    output=self.dropout(lstm_output)\n",
        "    output=self.finalLayer(output)\n",
        "    \n",
        "    #call the sigmoid function on current output of final layer\n",
        "    sigmoid_output=self.sigmoid(output)\n",
        "    sigmoid_output=sigmoid_output.view(batch_size,-1)\n",
        "    #only get the last position output for all batches\n",
        "    sigmoid_output=sigmoid_output[:,-1]\n",
        "    \n",
        "    #current sigmoid output and a hidden state to be fed as input for next pass\n",
        "    # into the LSTM cells, so that they will be dependent on the previous state\n",
        "    return sigmoid_output,hidden\n",
        "  \n",
        "  def initialize_hidden_state(self,batch_size):\n",
        "    # At first the hidden state will not hold any information, hence we need to\n",
        "    # initialize them with zeros\n",
        "    # Number_of_Layers x Batch_Size x Hidden_Dimension\n",
        "    weight=next(self.parameters()).data\n",
        "    if(torch.cuda.is_available()):\n",
        "      # if GPU is available then initialize the weights parallely\n",
        "      hidden=(weight.new(self.number_of_layers,batch_size,self.hidden_dimension).zero_().cuda(),weight.new(self.number_of_layers,batch_size,self.hidden_dimension).zero_().cuda())\n",
        "    else:\n",
        "      hidden=(weight.new(self.number_of_layers,batch_size,self.hidden_dimension).zero_(),weight.new(self.number_of_layers,batch_size,self.hidden_dimension).zero_())\n",
        "      \n",
        "    return hidden\n",
        "      \n",
        "   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "136bBBgPVpKm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torch.optim import Optimizer\n",
        "import  math\n",
        "class AdamOptimizerAlgorithm(Optimizer):\n",
        "  \n",
        "    \n",
        "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8):\n",
        "        defaults = dict(lr=lr, betas=betas, eps=eps)\n",
        "        super(AdamOptimizerAlgorithm, self).__init__(params, defaults)\n",
        "\n",
        "    def step(self):\n",
        "        for group in self.param_groups:\n",
        "            for p in group['params']:\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "                grad = p.grad.data\n",
        "                state = self.state[p]\n",
        "\n",
        "                # State initialization in case of initial state\n",
        "                if len(state) == 0:\n",
        "                    state['step'] = 0\n",
        "                    # Exponential moving average of gradient values\n",
        "                    state['exp_avg'] = torch.zeros_like(p.data)\n",
        "                    # Exponential moving average of squared gradient values\n",
        "                    state['exp_avg_sq'] = torch.zeros_like(p.data)\n",
        "                    \n",
        "\n",
        "                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n",
        "                \n",
        "                beta1, beta2 = group['betas']\n",
        "\n",
        "                state['step'] += 1\n",
        "\n",
        "                #following is just a formula implementaion of the algorithm\n",
        "                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n",
        "                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
        "                \n",
        "                denom = exp_avg_sq.sqrt().add_(group['eps'])\n",
        "\n",
        "                b_1 = 1 - beta1 ** state['step']\n",
        "                b_2 = 1 - beta2 ** state['step']\n",
        "                step_size = group['lr'] * math.sqrt(b_2) / b_1\n",
        "                \n",
        "                p.data.addcdiv_(-step_size, exp_avg, denom)  # -step_size*(exp_avg/denom) operation done in single step\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "a41iJq2QGqAP",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def buildNetwork():\n",
        "  #Our model parameters\n",
        "  vocabulary_size=len(vocab_to_int)+1\n",
        "  output_size=1\n",
        "  embedding_dimension=600\n",
        "  hidden_dimension=512\n",
        "  number_of_layers=3\n",
        "  \n",
        "  model=SentimentNetwork(vocabulary_size,output_size,embedding_dimension,hidden_dimension,number_of_layers)\n",
        "  \n",
        "  # Alpha value\n",
        "  learning_rate=0.003\n",
        "  \n",
        "  # Error calculating formula (Mean Square Error)\n",
        "  criterion = nn.MSELoss() \n",
        " \n",
        "  #Adam optimization technique for first-order gradient-based optimization\n",
        "  optimizer=AdamOptimizerAlgorithm(model.parameters(),lr=learning_rate)\n",
        "  \n",
        "  \n",
        "  return model,criterion,optimizer\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "9uf1QFQPT5Ra",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def trainNetwork(model,epochs,print_interval,criterion,optimizer):\n",
        "  Iteration=[]\n",
        "  Training_Loss=[]\n",
        "  Validation_Loss=[]\n",
        "  \n",
        "  minimum_validation_loss=np.Inf\n",
        "  \n",
        "  # Since each epoch goes over all data and\n",
        "  # each iteration goes over the data in batches\n",
        "  count=0\n",
        "  \n",
        "  # move model to GPU \n",
        "  model.cuda()\n",
        "  \n",
        "  #put the model into training model so that the gradients will \n",
        "  # be calculated\n",
        "  model.train()\n",
        "  for i in range(epochs):\n",
        "    # for each epoch perform a forward pass for all batches\n",
        "    # and around epoch 4 reduce the learning rate\n",
        "    hidden_state=model.initialize_hidden_state(batch_size)\n",
        "    \n",
        "    if(i==3):\n",
        "      print(\"\\n\\nReducing the learning rate!\\n\" )\n",
        "      #optimizer=torch.optim.Adam(model.parameters(),lr=0.0002)\n",
        "      optimizer=AdamOptimizerAlgorithm(model.parameters(),lr=0.0002)\n",
        "    \n",
        "    for inputs,labels in train_loader:\n",
        "      count+=1\n",
        "      # move the data to GPU\n",
        "      inputs,labels=inputs.cuda(),labels.cuda()\n",
        "      \n",
        "      #create new variable for hidden state otherwise it will include all\n",
        "      #pervious states\n",
        "      hidden_state=tuple([element.data for element in hidden_state])\n",
        "      \n",
        "      model.zero_grad()\n",
        "      \n",
        "      inputs=inputs.long()\n",
        "      output,hidden_state=model(inputs,hidden_state)\n",
        "      \n",
        "      #calculate the loss to backpropagare to model\n",
        "      #loss=torch.sqrt(criterion(output.squeeze(),labels.float()))\n",
        "      loss=criterion(output.squeeze(),labels.float())\n",
        "      loss.backward()\n",
        "\n",
        "      \n",
        "      #nn.utils.clip_grad_norm_(model.parameters(),clip)\n",
        "      optimizer.step()\n",
        "      \n",
        "      if(count%print_interval==0):\n",
        "        temp_hidden=model.initialize_hidden_state(batch_size)\n",
        "        temp_losses=[]\n",
        "        model.eval()\n",
        "        for inputs,labels in validation_loader:\n",
        "          temp_hidden=tuple([element.data for element in temp_hidden])\n",
        "          inputs,labels=inputs.cuda().long(),labels.cuda()\n",
        "          \n",
        "          output,temp_hidden=model(inputs,temp_hidden)\n",
        "          validation_loss=criterion(output.squeeze(),labels.float())\n",
        "          temp_losses.append(validation_loss.item())\n",
        "        \n",
        "        model.train()\n",
        "        print(\"Epoch: {}\\tIteration: {}\\tTraining Loss: {:.7f}\\tValidation Loss: {:.7f}\".format(\n",
        "        (i+1),count,loss.item(),np.mean(temp_losses)))\n",
        "        Iteration.append(count)\n",
        "        Training_Loss.append(loss.item())\n",
        "        Validation_Loss.append(np.mean(temp_losses))\n",
        "        \n",
        "        if np.mean(temp_losses)<minimum_validation_loss:\n",
        "            save_checkpoint(model,\"checkpoint.pth\")\n",
        "            minimum_validation_loss=np.mean(temp_losses)\n",
        "            print(\"Validation loss decreased  hence saving checkpoint successfully\")\n",
        "                  \n",
        "         \n",
        "\n",
        "\n",
        "  plt.plot(Iteration,Training_Loss)\n",
        "  plt.plot(Iteration,Validation_Loss)\n",
        "  plt.xlabel('Iteration')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.ylim(0.0,1.0)\n",
        "  plt.legend(['Training Loss','Validation Loss'], loc='upper left')\n",
        "  plt.show()\n",
        "  \n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "VMCv-pJkTL58",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def save_checkpoint(model,fileLocation):\n",
        "  # save the current state_dict which contains all the weights of the network\n",
        "  torch.save(model.state_dict(),fileLocation)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "DqJmKTYwTZjC",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_Checkpoint(fileLocation):\n",
        "  #model=buildNetwork()\n",
        "  model,criterion,optimizer=buildNetwork()\n",
        "  model.load_state_dict(torch.load(fileLocation))\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "UB0x9fla3AmK",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def checkAccuracy(model,test_loader):\n",
        "  #move model to GPU\n",
        "  model.cuda()\n",
        "  \n",
        "  test_losses=[]\n",
        "  correct_prediction=0\n",
        "  \n",
        "  #set initial state to zero\n",
        "  hidden_state=model.initialize_hidden_state(batch_size)\n",
        "  \n",
        "  # set the model into evaluation mode, so that we don't need to calculate\n",
        "  # the gradients\n",
        "  model.eval()\n",
        "  \n",
        "  for inputs,labels in test_loader:\n",
        "    \n",
        "    # move the data and labels into GPU\n",
        "    inputs,labels=inputs.cuda().long(),labels.cuda().long()\n",
        "    \n",
        "    output,hidden_state=model(inputs,hidden_state)\n",
        "    # labels are initially long or int, we need to conver them into float\n",
        "    # so that loss cab be calculated in float value\n",
        "    test_loss=criterion(output.squeeze(),labels.float())\n",
        "    test_losses.append(test_loss.item())\n",
        "    \n",
        "    # get the prediction either 1 or 0\n",
        "    prediction=torch.round(output.squeeze())\n",
        "    \n",
        "    correct_tensor=prediction.eq(labels.float().view_as(prediction))   \n",
        "    correct=np.squeeze(correct_tensor.cpu().numpy())\n",
        "    correct_prediction+=np.sum(correct)\n",
        "  \n",
        "  #print(np.mean(test_losses))\n",
        "  print(\"Accuracy: {:.4f}\".format(correct_prediction/len(test_loader.dataset)))\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "-DQjhHHKdjS-",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def tokenize_sentence(sentence):\n",
        "  sentence=sentence.lower()\n",
        "  \n",
        "  #remove punctuation\n",
        "  sentence=''.join([letter for letter in sentence if letter not in punctuation])\n",
        "  \n",
        "  test_words=sentence.split()\n",
        "  tokens=[]\n",
        "  sample=[]\n",
        "  for word in test_words:\n",
        "      if word in vocab_to_int:\n",
        "          sample.append(word)\n",
        "  tokens.append([vocab_to_int[word] for word in sample])\n",
        "  return tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "tFAQve__djXX",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def predict(model,sentence,sequence_length=200):\n",
        "  model.cuda()\n",
        "  model.eval()\n",
        "  \n",
        "  test_ints=tokenize_sentence(sentence)\n",
        "  features=featuresPadding(test_ints,sequence_length)\n",
        "  feature_tensor=torch.from_numpy(features)\n",
        "  batch_size=feature_tensor.size(0)\n",
        "  \n",
        "  hidden_state=model.initialize_hidden_state(batch_size)\n",
        "  feature_tensor=feature_tensor.cuda().long()\n",
        "  output,hidden_state=model(feature_tensor,hidden_state)\n",
        "  prediction=torch.round(output.squeeze())\n",
        "  if(prediction.item()==0):\n",
        "    print(\"{:.4f}\\t Negative sentence!\".format(output.item()))\n",
        "  else:\n",
        "    print(\"{:.4f}\\t Positive sentence!\".format(output.item()))\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "KZTaWPd2Gp1X",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "negativeDataPath=\"aclImdb/train/neg/\"\n",
        "positiveDataPath=\"aclImdb/train/pos/\"\n",
        "fileLocation='/content/drive/My Drive/SEM-III Project/SentimentAnalysisCheckpoint.pth'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "D1EoH7-hGp33",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "reviews,labels=createData(positiveDataPath,negativeDataPath)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "0yhFfFOzueUL",
        "outputId": "9d63f568-1aad-4afb-ac66-b418dd364808",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "len(reviews),len(labels)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(33151741, 225000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "DPVaPTNZIbSu",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "seq_length=200"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Pjak8byWGp5-",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "features,encoded_labels,vocab_to_int=getFeaturesLabels(reviews,labels,seq_length)\n",
        "\n",
        "train_x,train_y,test_x,test_y,val_x,val_y=createTrainTestValidateData(0.8,features,encoded_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "rP1Y1i4FGp8A",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
        "validation_data = TensorDataset(torch.from_numpy(val_x), torch.from_numpy(val_y))\n",
        "test_data = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))\n",
        "batch_size=100\n",
        "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
        "validation_loader = DataLoader(validation_data, shuffle=True, batch_size=batch_size)\n",
        "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "vxzyRGHMumss",
        "outputId": "b178d687-eebb-43cc-bbb9-a0a6f129b360",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"Training: \\t\",np.shape(train_x))\n",
        "print(\"Validation: \\t\",np.shape(val_x))\n",
        "print(\"Test: \\t\\t\",np.shape(test_x))\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training: \t (20000, 200)\n",
            "Validation: \t (2500, 200)\n",
            "Test: \t\t (2500, 200)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "UbEv55TFT5UK",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model,criterion,optimizer=buildNetwork()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "V3kFoVxm3AeW",
        "outputId": "c3f1f4b1-56f8-4f32-ade8-4dba136a7f5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "cell_type": "code",
      "source": [
        "model.cuda()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SentimentNetwork(\n",
              "  (embedding): Embedding(121365, 600)\n",
              "  (lstm): LSTM(600, 512, num_layers=3, batch_first=True, dropout=0.5)\n",
              "  (dropout): Dropout(p=0.5)\n",
              "  (finalLayer): Linear(in_features=512, out_features=1, bias=True)\n",
              "  (sigmoid): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ZS9jGePv3Ag1",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print_interval = 100\n",
        "epochs = 16 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "enEkdI103Ajl",
        "outputId": "6dc67d0f-0374-4a1a-8d27-f6a7421ef3b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1031
        }
      },
      "cell_type": "code",
      "source": [
        "import time\n",
        "start_time=time.time()\n",
        "trainNetwork(model,epochs,print_interval,criterion,optimizer)\n",
        "print(\"\\n\\nTraining Time: {} minutes\".format((time.time()-start_time)/60))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1\tIteration: 100\tTraining Loss: 0.2418555\tValidation Loss: 0.2359691\n",
            "Validation loss decreased  hence saving checkpoint successfully\n",
            "Epoch: 1\tIteration: 200\tTraining Loss: 0.1766867\tValidation Loss: 0.1915403\n",
            "Validation loss decreased  hence saving checkpoint successfully\n",
            "Epoch: 2\tIteration: 300\tTraining Loss: 0.1953648\tValidation Loss: 0.1558252\n",
            "Validation loss decreased  hence saving checkpoint successfully\n",
            "Epoch: 2\tIteration: 400\tTraining Loss: 0.1183145\tValidation Loss: 0.1264227\n",
            "Validation loss decreased  hence saving checkpoint successfully\n",
            "Epoch: 3\tIteration: 500\tTraining Loss: 0.0701459\tValidation Loss: 0.1303956\n",
            "Epoch: 3\tIteration: 600\tTraining Loss: 0.0913621\tValidation Loss: 0.1347342\n",
            "\n",
            "\n",
            "Reducing the learning rate!\n",
            "\n",
            "Epoch: 4\tIteration: 700\tTraining Loss: 0.0187498\tValidation Loss: 0.1279074\n",
            "Epoch: 4\tIteration: 800\tTraining Loss: 0.0281214\tValidation Loss: 0.1257939\n",
            "Validation loss decreased  hence saving checkpoint successfully\n",
            "Epoch: 5\tIteration: 900\tTraining Loss: 0.0450199\tValidation Loss: 0.1280346\n",
            "Epoch: 5\tIteration: 1000\tTraining Loss: 0.0244467\tValidation Loss: 0.1282429\n",
            "Epoch: 6\tIteration: 1100\tTraining Loss: 0.0295494\tValidation Loss: 0.1305099\n",
            "Epoch: 6\tIteration: 1200\tTraining Loss: 0.0104207\tValidation Loss: 0.1324596\n",
            "Epoch: 7\tIteration: 1300\tTraining Loss: 0.0230359\tValidation Loss: 0.1337625\n",
            "Epoch: 7\tIteration: 1400\tTraining Loss: 0.0175603\tValidation Loss: 0.1374276\n",
            "Epoch: 8\tIteration: 1500\tTraining Loss: 0.0315925\tValidation Loss: 0.1379397\n",
            "Epoch: 8\tIteration: 1600\tTraining Loss: 0.0194792\tValidation Loss: 0.1375286\n",
            "Epoch: 9\tIteration: 1700\tTraining Loss: 0.0100298\tValidation Loss: 0.1388796\n",
            "Epoch: 9\tIteration: 1800\tTraining Loss: 0.0298400\tValidation Loss: 0.1387108\n",
            "Epoch: 10\tIteration: 1900\tTraining Loss: 0.0102925\tValidation Loss: 0.1383559\n",
            "Epoch: 10\tIteration: 2000\tTraining Loss: 0.0104309\tValidation Loss: 0.1380666\n",
            "Epoch: 11\tIteration: 2100\tTraining Loss: 0.0103464\tValidation Loss: 0.1417695\n",
            "Epoch: 11\tIteration: 2200\tTraining Loss: 0.0000727\tValidation Loss: 0.1373071\n",
            "Epoch: 12\tIteration: 2300\tTraining Loss: 0.0000936\tValidation Loss: 0.1415522\n",
            "Epoch: 12\tIteration: 2400\tTraining Loss: 0.0001245\tValidation Loss: 0.1405720\n",
            "Epoch: 13\tIteration: 2500\tTraining Loss: 0.0025269\tValidation Loss: 0.1410832\n",
            "Epoch: 13\tIteration: 2600\tTraining Loss: 0.0003073\tValidation Loss: 0.1444580\n",
            "Epoch: 14\tIteration: 2700\tTraining Loss: 0.0144143\tValidation Loss: 0.1422861\n",
            "Epoch: 14\tIteration: 2800\tTraining Loss: 0.0057060\tValidation Loss: 0.1455268\n",
            "Epoch: 15\tIteration: 2900\tTraining Loss: 0.0296322\tValidation Loss: 0.1441364\n",
            "Epoch: 15\tIteration: 3000\tTraining Loss: 0.0001388\tValidation Loss: 0.1419338\n",
            "Epoch: 16\tIteration: 3100\tTraining Loss: 0.0244618\tValidation Loss: 0.1424383\n",
            "Epoch: 16\tIteration: 3200\tTraining Loss: 0.0118945\tValidation Loss: 0.1441191\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Training Time: 41.66050688823064 minutes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "XoGaFKm9uI4h"
      },
      "cell_type": "markdown",
      "source": [
        "### Checking the overfitted model"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "eOdZ7QRfdjVt",
        "outputId": "08dd88b1-e79e-42f3-d4b8-5bacb040e81f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "checkAccuracy(model,test_loader)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8488\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "eUNkUWNlT5W5",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "checkAccuracy(model,train_loader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "GoKlgqs5u-7P",
        "outputId": "9764a006-f4b7-4213-ee93-a2e02f786f2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "checkAccuracy(model,validation_loader)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8296\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "21rRn9gT1IzG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "001be910-42db-48e5-c623-2309dd622418"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "torch.cuda.empty_cache"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function torch.cuda.empty_cache>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "8E5CtnYwuNMW"
      },
      "cell_type": "markdown",
      "source": [
        "### Checking the model which was saved as temporary checkpoint after validation loss decreased"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "T-iaBml6aJJX",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model2=load_Checkpoint(\"checkpoint.pth\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "b7gbNbK6bIa0",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "checkAccuracy(model2.cuda(),test_loader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "KfsrBvaDdVwH",
        "outputId": "32c873ed-6fee-4bb0-f2b0-e4943e026001",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "checkAccuracy(model2.cuda(),train_loader)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9385\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "VU-JgA8ddZc8",
        "outputId": "ae379527-0863-4a0a-a1e9-7b7098372220",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "checkAccuracy(model2.cuda(),validation_loader)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8212\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "AN1hxjVruXoO"
      },
      "cell_type": "markdown",
      "source": [
        "### Saving the perfectly trained model to google drive"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "5k9494IFbLgP",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# saving the trained model to google drive\n",
        "save_checkpoint(model2,fileLocation)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "cnMCx9gat3i1",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model3=load_Checkpoint(fileLocation)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "uxfi086st9q_",
        "outputId": "784ba4f9-465b-4cf5-d284-f2dd58d09658",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "checkAccuracy(model3.cuda(),test_loader)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8612\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "wmifuQ7Fu--X",
        "outputId": "27eaf42e-5cf3-406e-e9a8-22468286dab7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "predict(model2, 'Kamikaze album by eminem has to be one of the best albums that came out last year, other than few tracks, evey track was lit', seq_length)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9501\t Positive sentence!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "shAzjr2Lu_Br",
        "outputId": "6abec76c-502a-4b07-bf49-c92d5938e9a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "sentence = 'Drake published 3 trash albums this year,each song gave pain at different part of my brain  he deserves rotten tomatoes'\n",
        "predict(model2,sentence)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.4549\t Negative sentence!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hFWDi3GWaWld",
        "colab_type": "code",
        "outputId": "ef2d54c3-d9f0-4b06-fedc-89118134f72c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "predict(model2, 'this was the worst movie i have ever seen', seq_length)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0673\t Negative sentence!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FQgSeGtkVbFu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#saving the created dictonary for future use\n",
        "np.save(\"vocab_to_int.npy\", vocab_to_int)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}